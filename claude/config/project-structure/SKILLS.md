# Project Structure - Code Analyzer

## Overview

**code-analyzer** is a unified multi-language static code analysis framework (v0.16.0) following professional Python package standards. This is NOT a cookiecutter templateâ€”it's a production research project with a structured, extensible architecture.

## Directory Layout

```
code-analyzer/
â”œâ”€â”€ src/code_analyzer/              # Main package (36,863 LOC)
â”‚   â”œâ”€â”€ core/                       # Data models & core abstractions
â”‚   â”‚   â”œâ”€â”€ code_graph.py           # NetworkX graph representation
â”‚   â”‚   â”œâ”€â”€ enums.py                # Language, FQN format enums
â”‚   â”‚   â”œâ”€â”€ models.py               # Symbol, import, metadata models
â”‚   â”‚   â””â”€â”€ fully_qualified_name.py # FQN parsing & formatting
â”‚   â”œâ”€â”€ parsers/                    # Multi-language parsing adapters
â”‚   â”‚   â”œâ”€â”€ base.py                 # SourceParser abstract base
â”‚   â”‚   â”œâ”€â”€ python.py, go.py, etc   # Language-specific parsers
â”‚   â”‚   â””â”€â”€ file_handlers/          # Custom AST walkers per language
â”‚   â”œâ”€â”€ actions/                    # Analysis operations (Phase 3+)
â”‚   â”œâ”€â”€ tools/                      # Analysis tools & query interfaces
â”‚   â”‚   â”œâ”€â”€ graph_tools.py          # Graph algorithms (paths, neighbors)
â”‚   â”‚   â”œâ”€â”€ graph_query/            # Cypher-like DSL query engine
â”‚   â”‚   â”œâ”€â”€ metrics.py              # Complexity/cyclomatic metrics
â”‚   â”‚   â””â”€â”€ extractors.py           # Data extraction utilities
â”‚   â”œâ”€â”€ agent/                      # Agentic querying system
â”‚   â”œâ”€â”€ db/                         # Database persistence layer
â”‚   â”‚   â””â”€â”€ database_manager.py     # PostgreSQL + pgvector integration
â”‚   â”œâ”€â”€ tui/                        # Terminal UI components
â”‚   â”‚   â””â”€â”€ main.py                 # TUI entry point
â”‚   â””â”€â”€ __init__.py                 # Version: 0.16.0 (read from here)
â”‚
â”œâ”€â”€ tests/                          # Comprehensive test suite (77,437 LOC)
â”‚   â”œâ”€â”€ unit/                       # Unit tests (97 test files)
â”‚   â”‚   â”œâ”€â”€ core/                   # Tests for models, graphs, FQN
â”‚   â”‚   â”œâ”€â”€ parsers/                # Parser implementation tests
â”‚   â”‚   â”œâ”€â”€ tools/                  # Graph tools, metrics tests
â”‚   â”‚   â”œâ”€â”€ actions/, agent/, db/, tui/
â”‚   â”‚   â””â”€â”€ conftest.py             # Shared fixtures, global mocks
â”‚   â”œâ”€â”€ integration/                # Database persistence tests
â”‚   â”‚   â””â”€â”€ conftest.py             # DB connection auto-setup
â”‚   â”œâ”€â”€ spikes/                     # 14 research phases (098 files)
â”‚   â”‚   â”œâ”€â”€ 001_core_model/         # Core model validation
â”‚   â”‚   â”œâ”€â”€ 002_python_parser/      # Parser implementation
â”‚   â”‚   â”œâ”€â”€ 003_networkx_graph/     # Graph algorithms
â”‚   â”‚   â”œâ”€â”€ ... (004-014) ...       # Various research phases
â”‚   â”‚   â””â”€â”€ conftest.py             # Spike-wide fixtures
â”‚   â””â”€â”€ corpus/                     # Reference code samples (NOT executed)
â”‚
â”œâ”€â”€ docs/                           # MkDocs + Markdown documentation
â”‚   â”œâ”€â”€ adr/                        # 17 Architectural Decision Records
â”‚   â”‚   â”œâ”€â”€ index.md                # ADR index with validation status
â”‚   â”‚   â”œâ”€â”€ 0001-0017.md            # Individual ADRs
â”‚   â”‚   â””â”€â”€ templates/              # ADR & plan templates
â”‚   â”œâ”€â”€ vision.md, philosophy.md    # Design documentation
â”‚   â”œâ”€â”€ high_level_design.md        # Architecture & diagrams
â”‚   â”œâ”€â”€ language_parsers.md         # Parser capabilities
â”‚   â”œâ”€â”€ ROADMAP.md                  # Phase-based timeline
â”‚   â””â”€â”€ plans/                      # Implementation plans
â”‚
â”œâ”€â”€ etc/                            # Configuration & deployment
â”‚   â”œâ”€â”€ docker-compose.yml          # PostgreSQL + pgvector
â”‚   â””â”€â”€ init-db.sql                 # Database schema initialization
â”‚
â”œâ”€â”€ .github/workflows/              # CI/CD automation
â”‚   â”œâ”€â”€ validate.yml                # Unit tests (PR/push)
â”‚   â””â”€â”€ build-package.yml           # Package building & release
â”‚
â”œâ”€â”€ .claude/                        # Claude Code configuration
â”‚   â”œâ”€â”€ settings.json               # IDE integration settings
â”‚   â”œâ”€â”€ SKILLS_*.md                 # Knowledge base files
â”‚   â””â”€â”€ README.md                   # Claude Code instructions
â”‚
â”œâ”€â”€ pyproject.toml                  # Project metadata & dependencies
â”œâ”€â”€ pytest.ini                      # Test configuration
â”œâ”€â”€ Makefile                        # Development commands
â”œâ”€â”€ uv.lock                         # Locked dependency versions
â””â”€â”€ README.md, CHANGELOG.md         # Version history
```

## Key Structural Principles

### 1. **Modern Python Package Layout**

- **src/ directory layout**: Source code isolated from tests and build artifacts
- **No setup.py**: Uses `pyproject.toml` exclusively (PEP 517/518 compliant)
- **Dynamic versioning**: Version read from `src/code_analyzer/__init__.py`
- **Entry points**: CLI scripts defined in `pyproject.toml`

### 2. **Extensible Architecture**

The design follows a **4-layer pattern**:

```
Language Source Files (Python, Go, Java, etc.)
    â†“
Parsers (SourceParser implementations)
    â†“
Core Models (Symbol, Import, Metadata)
    â†“
Storage Layer (NetworkX Graph, PostgreSQL)
    â†“
Query/Analysis Tools (Graph algorithms, metrics)
```

**Core Classes**:
- `SourceParser`: Abstract base for language-specific parsers
- `CodeGraph`: NetworkX graph representation of codebase
- `Symbol`: Represents code definitions (functions, classes, variables)
- `Import`: Tracks dependencies and external packages
- `FullyQualifiedName`: Standardized naming convention

### 3. **Supported Languages (Framework-Ready)**

| Language | Status | Implementation |
|----------|--------|-----------------|
| Python | âœ… Full | AST-based parser with full introspection |
| Go | âœ… Full | ast package parsing |
| Java | âœ… Full | Tree-sitter integration |
| JavaScript | âœ… Full | Tree-sitter integration |
| Rust | âœ… Full | Tree-sitter integration |
| Makefile, TOML, YAML | âœ… Full | Custom parsers |
| SQL | ðŸ“‹ Framework-ready | Parser stub exists |
| Zig | ðŸ“‹ Framework-ready | Parser interface defined |

### 4. **Database & Persistence**

- **PostgreSQL** with **pgvector** extension (semantic embeddings)
- **Schema**: Auto-initialized via `etc/init-db.sql`
- **ORM**: Direct SQL via psycopg2 (no SQLAlchemy)
- **Docker**: `make docker-up` starts containerized PostgreSQL

### 5. **Graph Query Engine**

Custom Cypher-like DSL (`graph_query/`) for code querying:

```python
# Example: Find all functions calling a specific method
query = "MATCH (f:Function)-[calls]->(m:Method {name: 'process'}) RETURN f"
```

- **Parser**: Lark-based grammar parsing
- **Executor**: NetworkX graph traversal
- **Status**: ADR-0017, 35/35 core tests passing

## Development Workflow

### Standard Tasks

```bash
make env              # Create venv with all dependencies
make test             # Run all unit tests with coverage
make lint             # Check code style (ruff)
make format           # Auto-format code (ruff + isort)
make type-check       # Static type checking (mypy strict)
make docker-up        # Start PostgreSQL
```

### Adding a New Language Parser

1. Create `src/code_analyzer/parsers/<language>.py` extending `SourceParser`
2. Implement required methods: `parse_file()`, `extract_symbols()`, etc.
3. Add unit tests in `tests/unit/parsers/test_<language>.py`
4. Reference implementation: `src/code_analyzer/parsers/python.py`

### Adding New Analysis Tools

1. Create tool in `src/code_analyzer/tools/<tool_name>.py`
2. Operate on `CodeGraph` and `Symbol` models
3. Add comprehensive unit tests
4. Document in `docs/query_tools.md`

## Configuration Files

### pyproject.toml

Defines:
- **Project metadata**: name, version (dynamic), description
- **Dependencies**: 47+ core packages
- **Optional groups**: docs, dev dependencies
- **Tool configs**: ruff, mypy, pytest
- **Scripts**: CLI entry points

### pytest.ini

```ini
[pytest]
testpaths = ["tests/unit", "tests/integration"]
norecursedirs = ["tests/corpus", "tests/spikes"]  # Exclude from auto-discovery
```

- **Rationale**: Corpus provides test data; spikes are experimental

### Makefile

Over 20 targets organized into categories:
- **Environment**: `env`, `sync`, `lock`
- **Testing**: `test`, `py-test`, `py-test-all`
- **Code quality**: `lint`, `format`, `type-check`, `imports`
- **Docker**: `docker-up`, `docker-down`, `docker-fresh`
- **Cleanup**: `clean`

## Important Paths

| Purpose | Path |
|---------|------|
| Main package | `src/code_analyzer/` |
| Unit tests | `tests/unit/` |
| Research spikes | `tests/spikes/` |
| Test data | `tests/corpus/` |
| Architecture docs | `docs/adr/` |
| Database config | `etc/` |
| Version | `src/code_analyzer/__init__.py` |
| Dependencies | `pyproject.toml` + `uv.lock` |

## Key Patterns

### Lazy Evaluation Pipeline

Components use fluent API for deferred execution:

```python
analysis = CodeAnalyzer(project_path)
    .extract_symbols()
    .build_graph()
    .analyze_dependencies()
    .persist_to_db()
```

### Mocking in Tests

Global mock in `tests/unit/conftest.py` replaces `DatabaseManager` to avoid DB dependencies during unit testing.

### Hypothesis Validation

Spikes (14 research phases) validate ADRs before committing to production code.

## Performance Characteristics

- **Python parsing**: Full AST with symbol resolution
- **Graph traversal**: Optimized NetworkX algorithms
- **Temporal analysis**: Sub-second Git history processing (ADR-0012)
- **LLM enrichment**: Probabilistic with hash-based caching (ADR-0013)
