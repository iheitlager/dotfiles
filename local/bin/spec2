#!/usr/bin/env python3
# Copyright 2026 Ilja Heitlager
# SPDX-License-Identifier: Apache-2.0

# /// script
# requires-python = ">=3.11"
# dependencies = [
#   "rich>=13.0.0",
# ]
# ///
"""
spec2 - Python-based OpenSpec browser and validator

Interactive OpenSpec browser with fzf and comprehensive validation:
- Interactive fzf browser (default)
- List and status views
- Metadata and section validation
- Requirements and scenarios checking
- Reference integrity validation
- Configurable rules engine
- Coverage tracking

Usage:
    spec2                           Interactive fzf browser (default)
    spec2 list                      List all specs with metadata
    spec2 status                    Compact overview table
    spec2 validate                  Validate all specs
    spec2 validate <name>           Validate specific spec
    spec2 template                  Show OpenSpec template
    spec2 new <name> [category]     Create new spec from template
    spec2 check-links               Validate all references
    spec2 coverage                  Show reference coverage report
    spec2 stats                     Statistics across specs
    spec2 rules show                Show active rules
"""

import argparse
import json
import os
import re
import shutil
import subprocess
import sys
import tomllib
from dataclasses import dataclass, field, asdict
from enum import Enum
from pathlib import Path
from typing import Optional, List, Dict, Any
from urllib.parse import urlparse

# Auto-exec with uv if dependencies not available
try:
    from rich.console import Console
    from rich.table import Table
    from rich.panel import Panel
    from rich.syntax import Syntax
    from rich import box
except ImportError:
    # Check if we can use uv to run this script
    if os.environ.get("SPEC2_NO_AUTO_UV") != "1":
        try:
            # Re-exec using uv
            script_path = Path(__file__).resolve()
            result = subprocess.run(
                ["uv", "run", "--script", str(script_path)] + sys.argv[1:],
                check=False
            )
            sys.exit(result.returncode)
        except FileNotFoundError:
            pass

    # Fallback error message
    print("Error: rich library not found. Run with: uv run --script spec2", file=sys.stderr)
    print("Or install rich: uv pip install rich", file=sys.stderr)
    sys.exit(1)

# =============================================================================
# DATA MODELS
# =============================================================================

class Severity(Enum):
    """Issue severity levels"""
    ERROR = "ERROR"
    WARNING = "WARNING"
    INFO = "INFO"

@dataclass
class ValidationIssue:
    """A validation issue found in a spec"""
    severity: Severity
    rule: str
    message: str
    line_number: Optional[int] = None
    section: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        return {
            "severity": self.severity.value,
            "rule": self.rule,
            "message": self.message,
            "line_number": self.line_number,
            "section": self.section,
        }

@dataclass
class SpecMetadata:
    """Metadata extracted from spec frontmatter"""
    title: str
    domain: Optional[str] = None
    version: Optional[str] = None
    status: Optional[str] = None
    date: Optional[str] = None
    owner: Optional[str] = None
    issue: Optional[str] = None
    custom_fields: Dict[str, str] = field(default_factory=dict)

    def to_dict(self) -> Dict[str, Any]:
        result = {
            "title": self.title,
            "domain": self.domain,
            "version": self.version,
            "status": self.status,
            "date": self.date,
        }
        if self.owner:
            result["owner"] = self.owner
        if self.issue:
            result["issue"] = self.issue
        if self.custom_fields:
            result["custom_fields"] = self.custom_fields
        return result

@dataclass
class Requirement:
    """A requirement with scenarios"""
    name: str
    statement: str
    scenarios: List[Dict[str, Any]] = field(default_factory=list)
    line_number: Optional[int] = None

@dataclass
class Reference:
    """A reference link in the spec"""
    text: str
    target: str
    line_number: Optional[int] = None
    ref_type: Optional[str] = None  # 'adr', 'test', 'source', 'external', 'internal'
    exists: Optional[bool] = None

@dataclass
class ValidationResult:
    """Complete validation result for a spec"""
    spec_file: str
    metadata: Optional[SpecMetadata]
    issues: List[ValidationIssue] = field(default_factory=list)
    requirements: List[Requirement] = field(default_factory=list)
    references: List[Reference] = field(default_factory=list)

    def has_errors(self) -> bool:
        return any(issue.severity == Severity.ERROR for issue in self.issues)

    def has_warnings(self) -> bool:
        return any(issue.severity == Severity.WARNING for issue in self.issues)

    def error_count(self) -> int:
        return sum(1 for issue in self.issues if issue.severity == Severity.ERROR)

    def warning_count(self) -> int:
        return sum(1 for issue in self.issues if issue.severity == Severity.WARNING)

    def info_count(self) -> int:
        return sum(1 for issue in self.issues if issue.severity == Severity.INFO)

    def to_dict(self) -> Dict[str, Any]:
        return {
            "spec_file": self.spec_file,
            "metadata": self.metadata.to_dict() if self.metadata else None,
            "issues": [issue.to_dict() for issue in self.issues],
            "error_count": self.error_count(),
            "warning_count": self.warning_count(),
            "info_count": self.info_count(),
        }

# =============================================================================
# CONFIGURATION AND RULES
# =============================================================================

DEFAULT_RULES = {
    "spec2": {
        "version": "1.0",
        "profile": "standard",
    },
    "validation": {
        "metadata": {
            "required": ["Domain", "Version", "Status", "Date"],
            "recommended": ["Owner"],
            "optional": ["Issue", "Priority"],
        },
        "sections": {
            "required": ["Overview", "RFC 2119 Keywords", "ADDED Requirements"],
            "recommended": ["Philosophy", "Key Capabilities", "References"],
        },
        "requirements": {
            "must_have_scenarios": True,
            "require_given_when_then": True,
            "require_rfc2119_keywords": True,
        },
        "references": {
            "check_adr_links": True,
            "check_test_links": True,
            "check_source_links": True,
            "adr_path": "docs/adr",
            "test_paths": ["tests/unit", "tests/integration", "tests/bdd"],
        },
    },
    "reporting": {
        "fail_on_warning": False,
    },
}

PROFILE_OVERRIDES = {
    "strict": {
        "validation": {
            "metadata": {
                "required": ["Domain", "Version", "Status", "Date", "Owner"],
            },
            "sections": {
                "required": ["Overview", "RFC 2119 Keywords", "ADDED Requirements", "Philosophy", "Key Capabilities", "References"],
            },
        },
        "reporting": {
            "fail_on_warning": True,
        },
    },
    "lenient": {
        "validation": {
            "metadata": {
                "required": ["Domain", "Status"],
            },
            "sections": {
                "required": ["Overview", "ADDED Requirements"],
            },
            "requirements": {
                "must_have_scenarios": False,
                "require_given_when_then": False,
            },
        },
    },
}

def load_rules(spec_dir: Path, profile: Optional[str] = None) -> Dict[str, Any]:
    """Load and merge rules from rules.toml with defaults"""
    rules = DEFAULT_RULES.copy()

    # Try to load project-specific rules
    rules_file = spec_dir / "rules.toml"
    if rules_file.exists():
        try:
            with open(rules_file, "rb") as f:
                project_rules = tomllib.load(f)
                # Deep merge
                rules = deep_merge(rules, project_rules)
        except Exception as e:
            print(f"Warning: Failed to load {rules_file}: {e}", file=sys.stderr)

    # Apply profile overrides
    profile_name = profile or rules.get("spec2", {}).get("profile", "standard")
    if profile_name in PROFILE_OVERRIDES:
        rules = deep_merge(rules, PROFILE_OVERRIDES[profile_name])

    return rules

def deep_merge(base: Dict, override: Dict) -> Dict:
    """Deep merge two dictionaries"""
    result = base.copy()
    for key, value in override.items():
        if key in result and isinstance(result[key], dict) and isinstance(value, dict):
            result[key] = deep_merge(result[key], value)
        else:
            result[key] = value
    return result

# =============================================================================
# RENDERING AND DISPLAY
# =============================================================================

# Global rendering mode (can be set via --raw flag)
RAW_MODE = False

def get_markdown_formatter() -> List[str]:
    """Determine markdown formatter command"""
    if RAW_MODE:
        # Raw mode: use bat for syntax highlighting only
        if shutil.which("bat"):
            return ["bat", "--style=plain", "--color=always", "--language=markdown"]
        return ["cat"]
    else:
        # Default: use glow for beautiful markdown rendering
        if shutil.which("glow"):
            return ["glow", "-s", "dark"]
        elif shutil.which("bat"):
            return ["bat", "--style=plain", "--color=always", "--language=markdown"]
        return ["cat"]

def render_markdown(file_path: Path, line_number: int = 1):
    """Render markdown file with highlighting at specific line"""
    formatter = get_markdown_formatter()

    try:
        if formatter[0] == "bat":
            # bat can highlight specific lines
            subprocess.run(
                formatter + [f"--highlight-line={line_number}", str(file_path)],
                check=False
            )
        elif formatter[0] == "glow":
            # glow renders beautifully but doesn't support line highlighting
            subprocess.run(formatter + [str(file_path)], check=False)
        else:
            # cat fallback
            subprocess.run(formatter + [str(file_path)], check=False)
    except Exception as e:
        console.print(f"[yellow]Warning:[/yellow] Failed to render: {e}")
        # Fallback to cat
        subprocess.run(["cat", str(file_path)], check=False)

# =============================================================================
# SPEC FILE DISCOVERY
# =============================================================================

def find_spec_dir(start_dir: Path = None, explicit_name: str = None) -> Optional[Path]:
    """Find spec directory searching multiple locations and names"""
    # Directory name candidates (in order of preference)
    candidates = [".openspec", "openspec", ".specs", "specs", ".spec", "spec"]

    # If explicit name provided, only check that
    if explicit_name:
        candidates = [explicit_name]

    # Start from current directory if not specified
    if start_dir is None:
        start_dir = Path.cwd()

    # First, check if we're in a git repository
    try:
        result = subprocess.run(
            ["git", "rev-parse", "--show-toplevel"],
            cwd=start_dir,
            capture_output=True,
            text=True,
            check=False
        )
        if result.returncode == 0:
            git_root = Path(result.stdout.strip())
            # Check candidates in git root
            for candidate in candidates:
                spec_dir = git_root / candidate
                if spec_dir.is_dir():
                    return spec_dir
    except FileNotFoundError:
        pass  # git not available

    # Check current directory and parents
    current = start_dir.resolve()
    for _ in range(10):  # Limit upward search to 10 levels
        for candidate in candidates:
            spec_dir = current / candidate
            if spec_dir.is_dir():
                return spec_dir

        # Move up one directory
        parent = current.parent
        if parent == current:  # Reached root
            break
        current = parent

    return None

def find_spec_files(spec_dir: Path) -> List[Path]:
    """Find all spec files, excluding templates"""
    spec_files = []

    # Pattern 1: Directory-based (001-name/spec.md)
    specs_subdir = spec_dir / "specs"
    if specs_subdir.exists():
        spec_files.extend(specs_subdir.glob("*/spec.md"))

    # Pattern 2: Named files (category/name.spec.md)
    spec_files.extend(spec_dir.glob("*/*.spec.md"))

    # Exclude templates
    excluded = [
        spec_dir / "template.md",
        spec_dir / "template.spec.md",
    ]

    # Filter out templates and files with "template" in name
    return [
        f for f in spec_files
        if f not in excluded
        and "template" not in f.name.lower()
        and f.parent.name != "template"
    ]

def find_spec_by_name(spec_dir: Path, name: str) -> Optional[Path]:
    """Find a specific spec by name or number"""
    all_specs = find_spec_files(spec_dir)

    for spec in all_specs:
        # Check if name matches directory name (e.g., "001-shortcuts" or "shortcuts")
        if spec.parent.name == name or spec.parent.name.endswith(f"-{name}"):
            return spec
        # Check if name matches file name
        if spec.stem == name or spec.name == name:
            return spec

    return None

# =============================================================================
# SPEC PARSING
# =============================================================================

def parse_spec_file(spec_path: Path) -> tuple[Optional[SpecMetadata], List[str], Dict[str, List[str]]]:
    """Parse spec file and extract metadata, lines, and sections"""
    with open(spec_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()

    # Extract metadata from first few lines
    metadata = extract_metadata(lines)

    # Parse sections
    sections = parse_sections(lines)

    return metadata, lines, sections

def extract_metadata(lines: List[str]) -> Optional[SpecMetadata]:
    """Extract metadata from spec frontmatter"""
    # Look for metadata in first 20 lines
    metadata_fields = {}
    title = None

    for i, line in enumerate(lines[:20]):
        line_stripped = line.strip()

        # Extract title from first heading
        if line_stripped.startswith("# ") and not title:
            title = line_stripped[2:].strip()
            continue

        # Extract metadata fields (format: **Field:** value)
        # Pattern: **Word:** value (colon is inside the asterisks)
        match = re.match(r'\*\*([^*]+):\*\*\s*(.+)', line_stripped)
        if match:
            field_name = match.group(1).strip()
            field_value = match.group(2).strip()
            # Remove markdown links, keeping just the text
            field_value = re.sub(r'\[([^\]]+)\]\([^\)]+\)', r'\1', field_value)
            metadata_fields[field_name] = field_value

    if not title:
        return None

    return SpecMetadata(
        title=title,
        domain=metadata_fields.get("Domain"),
        version=metadata_fields.get("Version"),
        status=metadata_fields.get("Status"),
        date=metadata_fields.get("Date"),
        owner=metadata_fields.get("Owner"),
        issue=metadata_fields.get("Issue"),
        custom_fields={k: v for k, v in metadata_fields.items()
                      if k not in ["Domain", "Version", "Status", "Date", "Owner", "Issue"]},
    )

def parse_sections(lines: List[str]) -> Dict[str, List[str]]:
    """Parse spec into sections based on ## and ### headings"""
    sections = {}
    current_section = None
    current_lines = []

    for line in lines:
        # Check for both ## (main sections) and ### (subsections)
        if line.startswith("## "):
            # Save previous section
            if current_section:
                sections[current_section] = current_lines
            # Start new section
            current_section = line[3:].strip()
            current_lines = []
        elif line.startswith("### ") and not line.startswith("### Requirement"):
            # Also track subsections (but not requirements)
            # Save previous section
            if current_section:
                sections[current_section] = current_lines
            # Start new subsection
            current_section = line[4:].strip()
            current_lines = []
        elif current_section:
            current_lines.append(line)

    # Save last section
    if current_section:
        sections[current_section] = current_lines

    return sections

def extract_requirements(lines: List[str], sections: Dict[str, List[str]]) -> List[Requirement]:
    """Extract requirements from ADDED Requirements section"""
    requirements = []

    # Find ADDED Requirements section
    added_req_section = None
    for section_name in sections:
        if "ADDED" in section_name and "Requirement" in section_name:
            added_req_section = section_name
            break

    if not added_req_section:
        return requirements

    section_lines = sections[added_req_section]
    current_req = None

    for i, line in enumerate(section_lines):
        line_stripped = line.strip()

        # Detect requirement heading (### Requirement: Name)
        if line_stripped.startswith("### Requirement:") or line_stripped.startswith("### "):
            if current_req:
                requirements.append(current_req)

            req_name = line_stripped.replace("### Requirement:", "").replace("###", "").strip()
            current_req = Requirement(name=req_name, statement="", scenarios=[], line_number=i+1)

        # Extract scenarios (#### Scenario: Name)
        elif line_stripped.startswith("#### Scenario:"):
            scenario_name = line_stripped.replace("#### Scenario:", "").strip()
            if current_req:
                current_req.scenarios.append({"name": scenario_name, "steps": []})

        # Extract scenario steps (GIVEN/WHEN/THEN/AND)
        # IMPORTANT: Check this BEFORE requirement statement to avoid capturing steps as statements
        elif line_stripped.startswith("- ") and current_req and current_req.scenarios:
            step = line_stripped[2:].strip()
            current_req.scenarios[-1]["steps"].append(step)

        # Extract requirement statement (contains MUST/SHALL/SHOULD)
        # Checked AFTER scenario steps to avoid misclassifying steps like "THEN it SHALL..."
        elif current_req and any(keyword in line_stripped.upper() for keyword in ["MUST", "SHALL", "SHOULD", "MAY"]):
            if not current_req.statement:
                current_req.statement = line_stripped

        # Capture continuation lines (indented content under a step)
        # These are lines that are indented but don't start with - or #
        elif (line.startswith(("  ", "\t")) and
              not line_stripped.startswith(("-", "#", "###", "####")) and
              line_stripped and
              current_req and
              current_req.scenarios and
              current_req.scenarios[-1]["steps"]):
            # Append to the last step as continuation
            current_req.scenarios[-1]["steps"][-1] += " " + line_stripped

    if current_req:
        requirements.append(current_req)

    return requirements

def extract_references(lines: List[str]) -> List[Reference]:
    """Extract markdown links from spec"""
    references = []
    link_pattern = re.compile(r'\[([^\]]+)\]\(([^\)]+)\)')

    for i, line in enumerate(lines):
        matches = link_pattern.findall(line)
        for text, target in matches:
            ref = Reference(text=text, target=target, line_number=i+1)

            # Classify reference type
            if target.startswith(('http://', 'https://', 'ftp://')):
                ref.ref_type = 'external'
            elif '/adr/' in target or target.startswith('adr/'):
                ref.ref_type = 'adr'
            elif '/test' in target or target.startswith('test'):
                ref.ref_type = 'test'
            elif target.endswith(('.py', '.js', '.ts', '.java', '.go', '.rs')):
                ref.ref_type = 'source'
            else:
                ref.ref_type = 'internal'

            references.append(ref)

    return references

# =============================================================================
# VALIDATION
# =============================================================================

def validate_metadata(metadata: Optional[SpecMetadata], rules: Dict[str, Any]) -> List[ValidationIssue]:
    """Validate spec metadata against rules"""
    issues = []

    if not metadata:
        issues.append(ValidationIssue(
            severity=Severity.ERROR,
            rule="metadata.missing",
            message="No metadata found in spec file"
        ))
        return issues

    metadata_rules = rules.get("validation", {}).get("metadata", {})
    required_fields = metadata_rules.get("required", [])
    recommended_fields = metadata_rules.get("recommended", [])

    # Check required fields
    for field in required_fields:
        value = getattr(metadata, field.lower(), None)
        if not value:
            issues.append(ValidationIssue(
                severity=Severity.ERROR,
                rule=f"metadata.required.{field.lower()}",
                message=f"Required metadata field missing: {field}"
            ))

    # Check recommended fields
    for field in recommended_fields:
        value = getattr(metadata, field.lower(), None)
        if not value:
            issues.append(ValidationIssue(
                severity=Severity.WARNING,
                rule=f"metadata.recommended.{field.lower()}",
                message=f"Recommended metadata field missing: {field}"
            ))

    return issues

def validate_sections(sections: Dict[str, List[str]], rules: Dict[str, Any]) -> List[ValidationIssue]:
    """Validate spec sections against rules"""
    issues = []

    section_rules = rules.get("validation", {}).get("sections", {})
    required_sections = section_rules.get("required", [])
    recommended_sections = section_rules.get("recommended", [])

    # Normalize section names for comparison (case-insensitive, flexible matching)
    normalized_sections = {s.lower().strip(): s for s in sections.keys()}

    # Check required sections
    for required in required_sections:
        required_lower = required.lower()
        # Flexible matching: check if any section contains the required text
        found = any(required_lower in norm for norm in normalized_sections.keys())
        if not found:
            issues.append(ValidationIssue(
                severity=Severity.ERROR,
                rule=f"section.required.{required.lower().replace(' ', '_')}",
                message=f"Required section missing: {required}"
            ))

    # Check recommended sections
    for recommended in recommended_sections:
        recommended_lower = recommended.lower()
        found = any(recommended_lower in norm for norm in normalized_sections.keys())
        if not found:
            issues.append(ValidationIssue(
                severity=Severity.WARNING,
                rule=f"section.recommended.{recommended.lower().replace(' ', '_')}",
                message=f"Recommended section missing: {recommended}"
            ))

    return issues

def validate_requirements(requirements: List[Requirement], rules: Dict[str, Any]) -> List[ValidationIssue]:
    """Validate requirements against rules"""
    issues = []

    req_rules = rules.get("validation", {}).get("requirements", {})
    must_have_scenarios = req_rules.get("must_have_scenarios", True)
    require_gwt = req_rules.get("require_given_when_then", True)
    require_rfc2119 = req_rules.get("require_rfc2119_keywords", True)

    if not requirements:
        issues.append(ValidationIssue(
            severity=Severity.WARNING,
            rule="requirements.none_found",
            message="No requirements found in spec"
        ))
        return issues

    for req in requirements:
        # Check for RFC 2119 keywords in statement
        if require_rfc2119 and req.statement:
            has_keyword = any(kw in req.statement.upper() for kw in ["MUST", "SHALL", "SHOULD", "MAY"])
            if not has_keyword:
                issues.append(ValidationIssue(
                    severity=Severity.WARNING,
                    rule="requirements.missing_rfc2119",
                    message=f"Requirement '{req.name}' missing RFC 2119 keyword (MUST/SHALL/SHOULD/MAY)",
                    line_number=req.line_number
                ))

        # Check for scenarios
        if must_have_scenarios and not req.scenarios:
            issues.append(ValidationIssue(
                severity=Severity.WARNING,
                rule="requirements.missing_scenarios",
                message=f"Requirement '{req.name}' has no scenarios",
                line_number=req.line_number
            ))

        # Check scenario format (Given-When-Then)
        if require_gwt:
            for scenario in req.scenarios:
                steps = scenario.get("steps", [])
                has_given = any(s.upper().startswith("GIVEN") for s in steps)
                has_when = any(s.upper().startswith("WHEN") for s in steps)
                has_then = any(s.upper().startswith("THEN") for s in steps)

                if not (has_given and has_when and has_then):
                    issues.append(ValidationIssue(
                        severity=Severity.INFO,
                        rule="requirements.incomplete_gwt",
                        message=f"Scenario '{scenario['name']}' in '{req.name}' incomplete (missing GIVEN/WHEN/THEN)"
                    ))

    return issues

def validate_references(
    references: List[Reference],
    spec_file: Path,
    project_root: Path,
    rules: Dict[str, Any]
) -> List[ValidationIssue]:
    """Validate reference links exist"""
    issues = []

    ref_rules = rules.get("validation", {}).get("references", {})
    check_adr = ref_rules.get("check_adr_links", True)
    check_test = ref_rules.get("check_test_links", True)
    check_source = ref_rules.get("check_source_links", True)

    for ref in references:
        # Skip external URLs
        if ref.ref_type == 'external':
            ref.exists = True
            continue

        # Resolve project-root-relative path
        target_path = resolve_reference(ref.target, spec_file, project_root)
        ref.exists = target_path is not None and target_path.exists()

        # Report broken links based on type
        if not ref.exists:
            severity = Severity.WARNING

            # Determine if we should check this reference type
            if ref.ref_type == 'adr' and not check_adr:
                continue
            if ref.ref_type == 'test' and not check_test:
                continue
            if ref.ref_type == 'source' and not check_source:
                continue

            issues.append(ValidationIssue(
                severity=severity,
                rule=f"reference.broken.{ref.ref_type}",
                message=f"Broken {ref.ref_type} link: {ref.target}",
                line_number=ref.line_number
            ))

    return issues

def resolve_reference(ref_path: str, spec_file: Path, project_root: Path) -> Optional[Path]:
    """Resolve project-root-relative references to absolute paths"""
    # Skip external URLs
    if ref_path.startswith(('http://', 'https://', 'ftp://', 'mailto:')):
        return None

    # Remove any anchor fragments
    ref_path = ref_path.split('#')[0]

    # Resolve from project root (primary method)
    from_root = (project_root / ref_path).resolve()
    if from_root.exists():
        return from_root

    # Fallback: try spec-relative (for backward compatibility)
    if '../' in ref_path or './' in ref_path:
        relative = (spec_file.parent / ref_path).resolve()
        if relative.exists():
            return relative

    return None

def validate_spec(
    spec_path: Path,
    project_root: Path,
    rules: Dict[str, Any]
) -> ValidationResult:
    """Validate a single spec file"""
    metadata, lines, sections = parse_spec_file(spec_path)
    requirements = extract_requirements(lines, sections)
    references = extract_references(lines)

    result = ValidationResult(
        spec_file=str(spec_path),
        metadata=metadata,
        requirements=requirements,
        references=references,
    )

    # Run validators
    result.issues.extend(validate_metadata(metadata, rules))
    result.issues.extend(validate_sections(sections, rules))
    result.issues.extend(validate_requirements(requirements, rules))
    result.issues.extend(validate_references(references, spec_path, project_root, rules))

    return result

# =============================================================================
# OUTPUT FORMATTING
# =============================================================================

console = Console()

def print_validation_results(results: List[ValidationResult], format_type: str = "terminal"):
    """Print validation results in specified format"""
    if format_type == "json":
        print_json_results(results)
    else:
        print_terminal_results(results)

def print_json_results(results: List[ValidationResult]):
    """Print results as JSON"""
    output = {
        "results": [r.to_dict() for r in results],
        "summary": {
            "total_specs": len(results),
            "specs_with_errors": sum(1 for r in results if r.has_errors()),
            "specs_with_warnings": sum(1 for r in results if r.has_warnings()),
            "total_errors": sum(r.error_count() for r in results),
            "total_warnings": sum(r.warning_count() for r in results),
        }
    }
    print(json.dumps(output, indent=2))

def print_terminal_results(results: List[ValidationResult]):
    """Print results to terminal with rich formatting"""
    total_errors = 0
    total_warnings = 0
    total_info = 0

    for result in results:
        spec_name = Path(result.spec_file).parent.name

        # Create status indicator
        if result.has_errors():
            status = "[red]âœ— FAILED[/red]"
        elif result.has_warnings():
            status = "[yellow]âš  WARNINGS[/yellow]"
        else:
            status = "[green]âœ“ PASSED[/green]"

        # Print spec header
        console.print(f"\n{status} {spec_name}", style="bold")

        # Print issues if any
        if result.issues:
            for issue in result.issues:
                severity_color = {
                    Severity.ERROR: "red",
                    Severity.WARNING: "yellow",
                    Severity.INFO: "blue",
                }[issue.severity]

                location = f":{issue.line_number}" if issue.line_number else ""
                console.print(
                    f"  [{severity_color}]{issue.severity.value}[/{severity_color}] "
                    f"{issue.message} {location}",
                    style="dim"
                )

        total_errors += result.error_count()
        total_warnings += result.warning_count()
        total_info += result.info_count()

    # Print summary
    console.print("\n" + "=" * 60)
    console.print(f"Validated {len(results)} spec(s)", style="bold")

    if total_errors > 0:
        console.print(f"  [red]âœ— {total_errors} error(s)[/red]")
    if total_warnings > 0:
        console.print(f"  [yellow]âš  {total_warnings} warning(s)[/yellow]")
    if total_info > 0:
        console.print(f"  [blue]â„¹ {total_info} info[/blue]")

    if total_errors == 0 and total_warnings == 0:
        console.print("  [green]âœ“ All specs valid[/green]")

# =============================================================================
# PROJECT INITIALIZATION
# =============================================================================

def init_project(project_folder: Path, spec_dir_name: str = ".openspec"):
    """Initialize OpenSpec directory structure in project"""
    spec_dir = project_folder / spec_dir_name

    # Create directories
    spec_dir.mkdir(exist_ok=True)
    (spec_dir / "specs").mkdir(exist_ok=True)

    console.print(f"[green]âœ“[/green] Created {spec_dir}/")
    console.print(f"[green]âœ“[/green] Created {spec_dir}/specs/")

    # Copy template
    template_source = find_template_file()
    if template_source:
        shutil.copy(template_source, spec_dir / "template.md")
        console.print(f"[green]âœ“[/green] Copied template to {spec_dir}/template.md")
    else:
        console.print("[yellow]âš [/yellow] Template not found, skipping")

    # Generate validate.py (copy of spec2 itself)
    spec2_source = Path(__file__).resolve()
    shutil.copy(spec2_source, spec_dir / "validate.py")
    (spec_dir / "validate.py").chmod(0o755)
    console.print(f"[green]âœ“[/green] Created {spec_dir}/validate.py")

    # Create rules example
    create_rules_example(spec_dir / "rules.toml.example")
    console.print(f"[green]âœ“[/green] Created {spec_dir}/rules.toml.example")

    # Create README
    create_readme(spec_dir / "README.md")
    console.print(f"[green]âœ“[/green] Created {spec_dir}/README.md")

    console.print(f"\n[bold green]âœ“ OpenSpec initialized in {spec_dir}[/bold green]")
    console.print("\nNext steps:")
    console.print(f"  1. Create a spec: mkdir {spec_dir}/specs/001-my-spec && cp {spec_dir}/template.md {spec_dir}/specs/001-my-spec/spec.md")
    console.print(f"  2. Edit your spec: vim {spec_dir}/specs/001-my-spec/spec.md")
    console.print(f"  3. Validate: spec2 validate --dir {spec_dir}")

def find_template_file() -> Optional[Path]:
    """Find the template.md file"""
    # Look in common locations
    search_paths = [
        Path.home() / ".dotfiles" / "local" / "share" / "spec" / "template.md",
        Path.home() / ".local" / "share" / "spec" / "template.md",
        Path("/usr/local/share/spec/template.md"),
        Path("/usr/share/spec/template.md"),
    ]

    for path in search_paths:
        if path.exists():
            return path

    return None

def create_rules_example(path: Path):
    """Create example rules.toml file"""
    content = '''# OpenSpec Validation Rules
# Copy to rules.toml to customize validation

[spec2]
version = "1.0"
profile = "standard"  # strict | standard | lenient

[validation.metadata]
required = ["Domain", "Version", "Status", "Date"]
recommended = ["Owner"]
optional = ["Issue", "Priority"]

[validation.sections]
required = ["Overview", "RFC 2119 Keywords", "ADDED Requirements"]
recommended = ["Philosophy", "Key Capabilities", "References"]

[validation.requirements]
must_have_scenarios = true
require_given_when_then = true
require_rfc2119_keywords = true

[validation.references]
check_adr_links = true
check_test_links = true
check_source_links = true
adr_path = "docs/adr"
test_paths = ["tests/unit", "tests/integration", "tests/bdd"]

[reporting]
fail_on_warning = false
'''
    with open(path, 'w') as f:
        f.write(content)

def create_readme(path: Path):
    """Create README.md for .openspec directory"""
    content = '''# OpenSpec Directory

This directory contains OpenSpec specification files for this project.

## Structure

- `specs/` - Individual specification files
- `template.md` - Template for new specs
- `validate.py` - Local validation script (copy of spec2)
- `rules.toml` - Project-specific validation rules (optional)

## Usage

### Create a new spec

```bash
mkdir specs/001-my-feature
cp template.md specs/001-my-feature/spec.md
# Edit the spec file
```

### Validate specs

```bash
# Using global spec2 command
spec2 validate

# Using local validator
./validate.py validate
```

### Validation Profiles

- **standard** (default): Balanced validation
- **strict**: All recommended fields required
- **lenient**: Minimal validation

Set profile in `rules.toml`:

```toml
[spec2]
profile = "strict"
```

## Reference Paths

All file references in specs should be **project-root-relative**:

- Good: `docs/adr/001-decision.md`
- Bad: `../../docs/adr/001-decision.md`

## More Information

Run `spec2 --help` for full command reference.
'''
    with open(path, 'w') as f:
        f.write(content)

# =============================================================================
# FZF INTERACTIVE BROWSER
# =============================================================================

def check_fzf_available() -> bool:
    """Check if fzf is installed"""
    return shutil.which("fzf") is not None

def build_fzf_list(spec_dir: Path) -> List[tuple]:
    """Build list of entries for fzf (files and requirements)"""
    entries = []
    spec_files = find_spec_files(spec_dir)

    for spec_file in spec_files:
        metadata, lines, sections = parse_spec_file(spec_file)
        requirements = extract_requirements(lines, sections)

        title = (metadata.title if metadata else spec_file.parent.name).strip().replace('\n', ' ')
        domain = (metadata.domain if metadata else "").strip().replace('\n', ' ')
        rel_path = spec_file.relative_to(spec_dir)

        # Add file entry
        entries.append(("FILE", str(spec_file), 1, title, domain))

        # Add requirement entries
        for req in requirements:
            req_name = req.name.strip().replace('\n', ' ')
            entries.append(("REQ", str(spec_file), req.line_number or 1, req_name, title))

    return entries

def format_fzf_entry(entry_type: str, line_num: int, name: str, meta: str) -> str:
    """Format entry for fzf display"""
    if entry_type == "FILE":
        return f"{line_num}|ðŸ“„ {name:<50}  {meta}"
    else:
        return f"{line_num}|   â””â”€ {name:<47}  {meta}"

def fzf_browser(spec_dir: Path, edit_mode: bool = False):
    """Interactive fzf browser for specs"""
    if not check_fzf_available():
        console.print("[red]Error:[/red] fzf not installed. Install with: brew install fzf")
        sys.exit(1)

    # Build selection list
    entries = build_fzf_list(spec_dir)

    if not entries:
        console.print(f"[yellow]No spec files found in {spec_dir}[/yellow]")
        return

    # Format for fzf
    fzf_input = "\n".join(
        format_fzf_entry(entry[0], entry[2], entry[3], entry[4])
        for entry in entries
    )

    # Create temp file for entry data
    import tempfile
    with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.txt') as tf:
        temp_file = tf.name
        for i, entry in enumerate(entries, 1):
            tf.write(f"{entry[0]}|{entry[1]}|{entry[2]}\n")

    # Get formatter for preview
    formatter = get_markdown_formatter()
    formatter_cmd = " ".join(formatter)

    # Preview command that reads from temp file
    preview_cmd = f'''
        line=$(sed -n "{{n}}p" {temp_file} | cut -d'|' -f3)
        file=$(sed -n "{{n}}p" {temp_file} | cut -d'|' -f2)
        {formatter_cmd} "$file" 2>/dev/null || cat "$file"
    '''

    try:
        # Run fzf
        result = subprocess.run(
            [
                "fzf",
                "--ansi",
                "--height=100%",
                "--layout=reverse",
                "--border",
                "--delimiter=|",
                "--with-nth=2..",
                "--prompt=OpenSpec > ",
                "--header=Enter: view | Ctrl-/: zoom | Ctrl-D: scroll down | Ctrl-U: scroll up",
                "--preview", preview_cmd,
                "--preview-window=right:60%:wrap",
                "--bind=ctrl-/:change-preview-window(80%|60%:wrap)",
                "--bind=ctrl-d:preview-half-page-down",
                "--bind=ctrl-u:preview-half-page-up",
            ],
            input=fzf_input,
            text=True,
            capture_output=True,
            check=False
        )

        if result.returncode == 0:
            # Get selected index
            selected_line = result.stdout.strip()
            # Find which entry was selected
            for i, entry in enumerate(entries, 1):
                if format_fzf_entry(entry[0], entry[2], entry[3], entry[4]) == selected_line:
                    selected_file = Path(entry[1])
                    selected_line_num = entry[2]

                    if edit_mode:
                        # Open in $EDITOR
                        editor = os.environ.get('EDITOR', 'nvim')
                        # Pass line number if editor supports it
                        if editor in ['vim', 'nvim', 'vi']:
                            subprocess.run([editor, f"+{selected_line_num}", str(selected_file)])
                        elif editor in ['code', 'subl']:
                            subprocess.run([editor, f"{selected_file}:{selected_line_num}"])
                        else:
                            subprocess.run([editor, str(selected_file)])
                    else:
                        # Render the selected spec
                        os.system('clear')
                        render_markdown(selected_file, selected_line_num)
                    break
    finally:
        # Cleanup temp file
        try:
            os.unlink(temp_file)
        except:
            pass

# =============================================================================
# LIST AND STATUS COMMANDS
# =============================================================================

def cmd_list(args):
    """List all specs with metadata and requirements"""
    # Try to find spec directory
    if args.dir == ".openspec":
        spec_dir = find_spec_dir()
        if not spec_dir:
            console.print("[red]Error:[/red] No spec directory found")
            sys.exit(1)
    else:
        spec_dir = Path(args.dir).resolve()
        if not spec_dir.exists():
            console.print(f"[red]Error:[/red] Directory not found: {spec_dir}")
            sys.exit(1)

    console.print(f"[bold]OpenSpec Files[/bold] [dim]({spec_dir})[/dim]\n")

    spec_files = find_spec_files(spec_dir)
    if not spec_files:
        console.print("[yellow]No spec files found[/yellow]")
        return

    for spec_file in spec_files:
        metadata, lines, sections = parse_spec_file(spec_file)
        requirements = extract_requirements(lines, sections)

        rel_path = spec_file.relative_to(spec_dir)
        title = metadata.title if metadata else spec_file.parent.name

        # Print spec header
        console.print(f"[bold green]{title}[/bold green]")
        console.print(f"  [dim]Path:[/dim]    {rel_path}")

        if metadata:
            if metadata.domain:
                console.print(f"  [dim]Domain:[/dim]  {metadata.domain}")
            if metadata.version:
                console.print(f"  [dim]Version:[/dim] {metadata.version}")
            if metadata.status:
                console.print(f"  [dim]Status:[/dim]  {metadata.status}")

        # List requirements
        if requirements:
            console.print(f"\n  [cyan]Requirements:[/cyan]")
            for req in requirements:
                line_info = f" [dim](line {req.line_number})[/dim]" if req.line_number else ""
                console.print(f"    [yellow]â€¢[/yellow] {req.name}{line_info}")

        console.print()

def cmd_status(args):
    """Show compact status overview"""
    # Try to find spec directory
    if args.dir == ".openspec":
        spec_dir = find_spec_dir()
        if not spec_dir:
            console.print("[red]Error:[/red] No spec directory found")
            sys.exit(1)
    else:
        spec_dir = Path(args.dir).resolve()
        if not spec_dir.exists():
            console.print(f"[red]Error:[/red] Directory not found: {spec_dir}")
            sys.exit(1)

    spec_files = find_spec_files(spec_dir)
    file_count = len(spec_files)

    console.print(f"[bold]OpenSpec Status[/bold] [dim]({spec_dir})[/dim]\n")
    console.print(f"Files: [green]{file_count}[/green]\n")

    # Create status table
    table = Table(box=box.SIMPLE)
    table.add_column("Specification", style="bold", width=50)
    table.add_column("Version", style="cyan", width=8)
    table.add_column("Status", style="green", width=12)
    table.add_column("Reqs", style="yellow", justify="right")

    total_reqs = 0

    for spec_file in spec_files:
        metadata, lines, sections = parse_spec_file(spec_file)
        requirements = extract_requirements(lines, sections)

        title = metadata.title if metadata else spec_file.parent.name
        version = metadata.version if metadata and metadata.version else "-"
        status = metadata.status if metadata and metadata.status else "-"
        req_count = len(requirements)

        total_reqs += req_count

        # Truncate title if too long
        if len(title) > 50:
            title = title[:47] + "..."

        table.add_row(title, version, status, str(req_count))

    console.print(table)
    console.print(f"\nTotal Requirements: [bold yellow]{total_reqs}[/bold yellow]")

# =============================================================================
# TEMPLATE AND NEW SPEC COMMANDS
# =============================================================================

def cmd_template(args):
    """Show the OpenSpec template"""
    template_file = find_template_file()

    if not template_file:
        console.print("[red]Error:[/red] Template not found")
        console.print("Searched in:")
        console.print("  - ~/.dotfiles/local/share/spec/template.md")
        console.print("  - ~/.local/share/spec/template.md")
        console.print("  - /usr/local/share/spec/template.md")
        console.print("  - /usr/share/spec/template.md")
        sys.exit(1)

    # Just cat the template (no formatting)
    with open(template_file, 'r') as f:
        print(f.read())

def cmd_new(args):
    """Create new spec from template"""
    # Try to find spec directory
    if args.dir == ".openspec":
        spec_dir = find_spec_dir()
        if not spec_dir:
            console.print("[red]Error:[/red] No spec directory found")
            console.print("Run 'spec2 init' to initialize OpenSpec")
            sys.exit(1)
    else:
        spec_dir = Path(args.dir).resolve()
        if not spec_dir.exists():
            console.print(f"[red]Error:[/red] Directory not found: {spec_dir}")
            console.print("Run 'spec2 init' to initialize OpenSpec")
            sys.exit(1)

    if not args.spec_name:
        console.print("[red]Error:[/red] Spec name required")
        console.print("Usage: spec2 new <spec-name> [category]")
        console.print("\nExamples:")
        console.print("  spec2 new authentication           # Creates directory-based spec")
        console.print("  spec2 new auth backend             # Creates backend/auth.spec.md")
        sys.exit(1)

    spec_name = args.spec_name
    category = args.category

    # Detect existing pattern
    spec_files = find_spec_files(spec_dir)
    has_named = any(f.name.endswith('.spec.md') and f.name != 'spec.md' for f in spec_files)
    has_directory = any(f.name == 'spec.md' for f in spec_files)

    # Determine target file
    if category or has_named:
        # Named file pattern
        if not category:
            category = "general"
        target_dir = spec_dir / category
        target_dir.mkdir(exist_ok=True)
        new_file = target_dir / f"{spec_name}.spec.md"
        console.print(f"[dim]Using named file pattern:[/dim] {category}/{spec_name}.spec.md")
    else:
        # Directory pattern
        specs_dir = spec_dir / "specs"
        specs_dir.mkdir(exist_ok=True)

        # Check for numbered directories
        existing_dirs = [d for d in specs_dir.iterdir() if d.is_dir()]
        max_num = 0
        has_numbered = False

        for d in existing_dirs:
            match = re.match(r'^(\d{3})-', d.name)
            if match:
                has_numbered = True
                num = int(match.group(1))
                if num > max_num:
                    max_num = num

        if has_numbered:
            next_num = f"{max_num + 1:03d}"
            dir_name = f"{next_num}-{spec_name}"
        else:
            dir_name = spec_name

        target_dir = specs_dir / dir_name
        target_dir.mkdir(exist_ok=True)
        new_file = target_dir / "spec.md"
        console.print(f"[dim]Using directory pattern:[/dim] {dir_name}/spec.md")

    if new_file.exists():
        console.print(f"[red]Error:[/red] Spec file already exists: {new_file}")
        sys.exit(1)

    # Copy template
    template_file = find_template_file()
    if not template_file:
        console.print("[yellow]Warning:[/yellow] Template not found, creating empty spec")
        new_file.write_text("# New Specification\n\nTODO: Add content\n")
    else:
        shutil.copy(template_file, new_file)

        # Replace date placeholder
        from datetime import date
        content = new_file.read_text()
        content = content.replace("[YYYY-MM-DD]", date.today().isoformat())
        new_file.write_text(content)

    console.print(f"[green]Created new spec:[/green] {new_file}")
    console.print("\n[dim]Next steps:[/dim]")
    console.print(f"  1. Edit the spec file: $EDITOR {new_file}")
    console.print(f"  2. Replace [placeholders] with your content")
    console.print(f"  3. Add requirements and scenarios")
    console.print(f"  4. Run: spec2 validate")

def cmd_browse(args):
    """Interactive fzf browser (default command)"""
    # Try to find spec directory
    if args.dir == ".openspec":
        spec_dir = find_spec_dir()
        if not spec_dir:
            console.print("[red]Error:[/red] No spec directory found")
            console.print("Searched for: .openspec, openspec, .spec, spec, .specs, specs")
            console.print("Run 'spec2 init' to initialize OpenSpec")
            sys.exit(1)
    else:
        spec_dir = Path(args.dir).resolve()
        if not spec_dir.exists():
            console.print(f"[red]Error:[/red] Directory not found: {spec_dir}")
            sys.exit(1)

    edit_mode = getattr(args, 'edit', False)
    fzf_browser(spec_dir, edit_mode)

# =============================================================================
# CLI COMMANDS
# =============================================================================

def cmd_init(args):
    """Initialize OpenSpec in project"""
    project_folder = Path(args.project_folder).resolve()
    init_project(project_folder, args.dir)

def cmd_validate(args):
    """Validate specs"""
    # Check if reading from stdin
    if not sys.stdin.isatty():
        # Read from stdin to temp file
        import tempfile
        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.md') as tf:
            temp_file = tf.name
            tf.write(sys.stdin.read())

        # Validate the temp file
        spec_path = Path(temp_file)
        project_root = Path.cwd()
        rules = DEFAULT_RULES.copy()

        result = validate_spec(spec_path, project_root, rules)

        # Determine output format
        output_format = "json" if args.json or (hasattr(args, 'format') and args.format == "json") else "terminal"
        print_validation_results([result], output_format)

        # Cleanup
        os.unlink(temp_file)

        # Exit code
        if result.has_errors():
            sys.exit(1)
        elif result.has_warnings() and args.fail_on_warning:
            sys.exit(2)
        else:
            sys.exit(0)

    # Try to find spec directory
    if args.dir == ".openspec":
        # Default case - search for any spec directory
        spec_dir = find_spec_dir()
        if not spec_dir:
            console.print(f"[red]Error:[/red] No spec directory found")
            console.print(f"Searched for: .openspec, openspec, .spec, spec, .specs, specs")
            console.print(f"Run 'spec2 init' to initialize OpenSpec")
            sys.exit(1)
    else:
        # Explicit directory provided
        spec_dir = Path(args.dir).resolve()
        if not spec_dir.exists():
            console.print(f"[red]Error:[/red] Directory not found: {spec_dir}")
            console.print(f"Run 'spec2 init' to initialize OpenSpec")
            sys.exit(1)

    project_root = Path(args.project_folder).resolve()

    # Load rules
    profile = "strict" if args.strict else None
    rules = load_rules(spec_dir, profile)

    # Override fail_on_warning if specified
    if args.fail_on_warning:
        rules["reporting"]["fail_on_warning"] = True

    # Find specs to validate
    if args.spec_name:
        spec_file = find_spec_by_name(spec_dir, args.spec_name)
        if not spec_file:
            console.print(f"[red]Error:[/red] Spec not found: {args.spec_name}")
            sys.exit(1)
        spec_files = [spec_file]
    else:
        spec_files = find_spec_files(spec_dir)

    if not spec_files:
        console.print(f"[yellow]No spec files found in {spec_dir}[/yellow]")
        sys.exit(0)

    # Validate each spec
    results = []
    for spec_file in spec_files:
        result = validate_spec(spec_file, project_root, rules)
        results.append(result)

    # Determine output format
    output_format = "json" if args.json or args.format == "json" else "terminal"

    # Print results
    print_validation_results(results, output_format)

    # Exit code
    has_errors = any(r.has_errors() for r in results)
    has_warnings = any(r.has_warnings() for r in results)
    fail_on_warning = rules["reporting"]["fail_on_warning"]

    if has_errors:
        sys.exit(1)
    elif has_warnings and fail_on_warning:
        sys.exit(2)
    else:
        sys.exit(0)

def cmd_stats(args):
    """Show statistics across specs"""
    # Try to find spec directory
    if args.dir == ".openspec":
        spec_dir = find_spec_dir()
        if not spec_dir:
            console.print(f"[red]Error:[/red] No spec directory found")
            sys.exit(1)
    else:
        spec_dir = Path(args.dir).resolve()

    project_root = Path(args.project_folder).resolve()

    spec_files = find_spec_files(spec_dir)
    if not spec_files:
        console.print(f"[yellow]No spec files found in {spec_dir}[/yellow]")
        return

    rules = load_rules(spec_dir)

    # Collect statistics
    total_requirements = 0
    total_scenarios = 0
    total_references = 0
    specs_by_status = {}

    for spec_file in spec_files:
        result = validate_spec(spec_file, project_root, rules)

        total_requirements += len(result.requirements)
        for req in result.requirements:
            total_scenarios += len(req.scenarios)
        total_references += len(result.references)

        if result.metadata:
            status = result.metadata.status or "Unknown"
            specs_by_status[status] = specs_by_status.get(status, 0) + 1

    # Print statistics
    console.print("\n[bold]OpenSpec Statistics[/bold]\n")
    console.print(f"Total Specs: {len(spec_files)}")
    console.print(f"Total Requirements: {total_requirements}")
    console.print(f"Total Scenarios: {total_scenarios}")
    console.print(f"Total References: {total_references}")

    console.print("\n[bold]Specs by Status:[/bold]")
    for status, count in sorted(specs_by_status.items()):
        console.print(f"  {status}: {count}")

def cmd_coverage(args):
    """Show reference coverage for each spec"""
    # Try to find spec directory
    if args.dir == ".openspec":
        spec_dir = find_spec_dir()
        if not spec_dir:
            console.print(f"[red]Error:[/red] No spec directory found")
            sys.exit(1)
    else:
        spec_dir = Path(args.dir).resolve()

    project_root = Path(args.project_folder).resolve()

    spec_files = find_spec_files(spec_dir)
    if not spec_files:
        console.print(f"[yellow]No spec files found in {spec_dir}[/yellow]")
        return

    rules = load_rules(spec_dir)

    # Create coverage table
    table = Table(title="Spec Reference Coverage", box=box.ROUNDED)
    table.add_column("Spec", style="cyan", no_wrap=True)
    table.add_column("Status", style="yellow")
    table.add_column("ADRs", justify="center")
    table.add_column("Tests", justify="center")
    table.add_column("Source", justify="center")
    table.add_column("External", justify="center")
    table.add_column("Total Refs", justify="right")

    # Collect coverage data
    coverage_data = []
    total_with_adrs = 0
    total_with_tests = 0
    total_with_source = 0

    for spec_file in spec_files:
        result = validate_spec(spec_file, project_root, rules)
        spec_name = spec_file.parent.name

        # Count references by type
        adr_refs = sum(1 for ref in result.references if ref.ref_type == 'adr')
        test_refs = sum(1 for ref in result.references if ref.ref_type == 'test')
        source_refs = sum(1 for ref in result.references if ref.ref_type == 'source')
        external_refs = sum(1 for ref in result.references if ref.ref_type == 'external')
        total_refs = len(result.references)

        # Track coverage
        if adr_refs > 0:
            total_with_adrs += 1
        if test_refs > 0:
            total_with_tests += 1
        if source_refs > 0:
            total_with_source += 1

        # Format cells with color
        adr_cell = f"[green]{adr_refs}[/green]" if adr_refs > 0 else f"[dim]{adr_refs}[/dim]"
        test_cell = f"[green]{test_refs}[/green]" if test_refs > 0 else f"[dim]{test_refs}[/dim]"
        source_cell = f"[green]{source_refs}[/green]" if source_refs > 0 else f"[dim]{source_refs}[/dim]"
        external_cell = f"[blue]{external_refs}[/blue]" if external_refs > 0 else f"[dim]{external_refs}[/dim]"

        status = result.metadata.status if result.metadata else "Unknown"

        table.add_row(
            spec_name,
            status,
            adr_cell,
            test_cell,
            source_cell,
            external_cell,
            str(total_refs)
        )

        coverage_data.append({
            "name": spec_name,
            "adr_refs": adr_refs,
            "test_refs": test_refs,
            "source_refs": source_refs,
            "total_refs": total_refs
        })

    console.print("\n")
    console.print(table)

    # Print coverage summary
    total_specs = len(spec_files)
    console.print(f"\n[bold]Coverage Summary:[/bold]")
    console.print(f"  Specs with ADR references: {total_with_adrs}/{total_specs} ({100*total_with_adrs//total_specs if total_specs > 0 else 0}%)")
    console.print(f"  Specs with test references: {total_with_tests}/{total_specs} ({100*total_with_tests//total_specs if total_specs > 0 else 0}%)")
    console.print(f"  Specs with source references: {total_with_source}/{total_specs} ({100*total_with_source//total_specs if total_specs > 0 else 0}%)")

    # List specs without coverage
    if args.verbose:
        console.print(f"\n[bold]Specs without test coverage:[/bold]")
        for data in coverage_data:
            if data["test_refs"] == 0:
                console.print(f"  [yellow]â€¢ {data['name']}[/yellow]")

        console.print(f"\n[bold]Specs without ADR references:[/bold]")
        for data in coverage_data:
            if data["adr_refs"] == 0:
                console.print(f"  [yellow]â€¢ {data['name']}[/yellow]")

def cmd_rules_show(args):
    """Show active rules"""
    # Try to find spec directory
    if args.dir == ".openspec":
        spec_dir = find_spec_dir()
        if not spec_dir:
            console.print(f"[red]Error:[/red] No spec directory found")
            sys.exit(1)
    else:
        spec_dir = Path(args.dir).resolve()

    rules = load_rules(spec_dir)

    console.print("\n[bold]Active Validation Rules[/bold]\n")
    console.print(f"Profile: {rules['spec2']['profile']}")
    console.print(f"\nRequired Metadata: {', '.join(rules['validation']['metadata']['required'])}")
    console.print(f"Required Sections: {', '.join(rules['validation']['sections']['required'])}")

def cmd_check_links(args):
    """Check all reference links for validity"""
    # Try to find spec directory
    if args.dir == ".openspec":
        spec_dir = find_spec_dir()
        if not spec_dir:
            console.print(f"[red]Error:[/red] No spec directory found")
            sys.exit(1)
    else:
        spec_dir = Path(args.dir).resolve()

    project_root = Path(args.project_folder).resolve()

    spec_files = find_spec_files(spec_dir)
    if not spec_files:
        console.print(f"[yellow]No spec files found in {spec_dir}[/yellow]")
        return

    rules = load_rules(spec_dir)

    # Check all references
    total_refs = 0
    broken_refs = 0
    refs_by_type = {}

    console.print("\n[bold]Checking Reference Links[/bold]\n")

    for spec_file in spec_files:
        result = validate_spec(spec_file, project_root, rules)
        spec_name = spec_file.parent.name

        # Find broken references
        spec_broken = []
        for ref in result.references:
            total_refs += 1
            ref_type = ref.ref_type or "unknown"
            refs_by_type[ref_type] = refs_by_type.get(ref_type, 0) + 1

            if ref.ref_type != 'external' and not ref.exists:
                broken_refs += 1
                spec_broken.append(ref)

        if spec_broken:
            console.print(f"[yellow]{spec_name}:[/yellow]")
            for ref in spec_broken:
                console.print(f"  [red]âœ—[/red] {ref.target} (line {ref.line_number})")

    # Summary
    console.print(f"\n[bold]Summary:[/bold]")
    console.print(f"  Total references: {total_refs}")
    console.print(f"  Broken links: [{'red' if broken_refs > 0 else 'green'}]{broken_refs}[/]")
    console.print(f"\n[bold]By type:[/bold]")
    for ref_type, count in sorted(refs_by_type.items()):
        console.print(f"  {ref_type}: {count}")

    if broken_refs == 0:
        console.print(f"\n[green]âœ“ All reference links are valid[/green]")
    else:
        sys.exit(1)

# =============================================================================
# MAIN CLI
# =============================================================================

def main():
    parser = argparse.ArgumentParser(
        description="""spec2 - Python-based OpenSpec browser and validator

Interactive OpenSpec browser with fzf and comprehensive validation.
Full feature parity with bash 'spec' command plus enhanced validation.""",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Commands:
  (none)           Interactive fzf browser (default)
  browse           Interactive fzf browser
  list             List all specs with metadata and requirements
  status           Show compact status overview table
  validate [name]  Validate all specs or specific spec (supports stdin)
  template         Show the OpenSpec template
  new <name> [cat] Create new spec from template
  init             Initialize .openspec/ in project
  stats            Show statistics across specs
  coverage         Show reference coverage report
  check-links      Validate all reference links
  rules show       Show active validation rules

Common Options (available on most commands):
  --dir DIR                 Spec directory (default: .openspec)
                            Auto-discovers: .openspec, openspec, .specs, specs, .spec, spec
  --project-folder PATH     Project root for resolving references (default: .)
  --raw                     Use raw mode (bat syntax highlighting instead of glow)
  --edit                    Open selected file in $EDITOR (browse only)
  --strict                  Use strict validation profile (validate only)
  --fail-on-warning         Exit code 2 on warnings (validate only)
  --json                    JSON output format (validate only)
  -v, --verbose             Verbose output (coverage only)

Examples:
  # Interactive browser
  spec2                                Interactive fzf browser (default)
  spec2 --raw                          Use bat instead of glow
  spec2 --edit                         Browse and edit in $EDITOR
  spec2 browse --dir custom-specs      Browse custom directory

  # List and status
  spec2 list                           List all specs with details
  spec2 status                         Compact status overview
  spec2 list --dir /path/specs         List from specific directory

  # Create and edit
  spec2 template                       Show OpenSpec template
  spec2 new authentication             Create new spec
  spec2 new auth backend               Create backend/auth.spec.md
  spec2 new myspec --dir custom        Create in custom directory

  # Validation
  spec2 validate                       Validate all specs
  spec2 validate shortcuts             Validate specific spec
  cat file.md | spec2 validate         Validate from stdin
  spec2 validate --strict              Use strict validation
  spec2 validate --project-folder ~/   Custom project root

  # Analysis
  spec2 coverage                       Show reference coverage report
  spec2 check-links                    Validate all reference links
  spec2 stats                          Show statistics
  spec2 rules show                     Show active rules

  # Advanced
  spec2 validate --fail-on-warning     Exit code 2 on warnings
  spec2 validate --json                JSON output
  spec2 coverage -v                    Show specs without coverage
        """
    )

    # Global flags
    parser.add_argument("--raw", action="store_true", help="Use raw mode (bat syntax highlighting instead of glow)")
    parser.add_argument("--edit", action="store_true", help="Open selected file in $EDITOR (browse mode)")

    subparsers = parser.add_subparsers(dest="command", help="Commands")

    # browse command (default)
    browse_parser = subparsers.add_parser("browse", help="Interactive fzf browser (default)")
    browse_parser.add_argument("--dir", default=".openspec", help="Spec directory (default: .openspec)")
    browse_parser.add_argument("--project-folder", default=".", help="Project root directory (default: current)")

    # list command
    list_parser = subparsers.add_parser("list", help="List all specs with metadata")
    list_parser.add_argument("--dir", default=".openspec", help="Spec directory (default: .openspec)")
    list_parser.add_argument("--project-folder", default=".", help="Project root directory (default: current)")

    # status command
    status_parser = subparsers.add_parser("status", help="Show compact status overview")
    status_parser.add_argument("--dir", default=".openspec", help="Spec directory (default: .openspec)")
    status_parser.add_argument("--project-folder", default=".", help="Project root directory (default: current)")

    # init command
    init_parser = subparsers.add_parser("init", help="Initialize OpenSpec in project")
    init_parser.add_argument("--dir", default=".openspec", help="Directory name (default: .openspec)")
    init_parser.add_argument("--project-folder", default=".", help="Project root directory (default: current)")

    # template command
    template_parser = subparsers.add_parser("template", help="Show the OpenSpec template")

    # new command
    new_parser = subparsers.add_parser("new", help="Create new spec from template")
    new_parser.add_argument("spec_name", nargs="?", help="Name of the new spec")
    new_parser.add_argument("category", nargs="?", help="Category for named file pattern (optional)")
    new_parser.add_argument("--dir", default=".openspec", help="Spec directory (default: .openspec)")
    new_parser.add_argument("--project-folder", default=".", help="Project root directory (default: current)")

    # validate command
    validate_parser = subparsers.add_parser("validate", help="Validate specs")
    validate_parser.add_argument("spec_name", nargs="?", help="Specific spec to validate")
    validate_parser.add_argument("--dir", default=".openspec", help="Spec directory (default: .openspec)")
    validate_parser.add_argument("--project-folder", default=".", help="Project root for resolving references")
    validate_parser.add_argument("--strict", action="store_true", help="Use strict validation profile")
    validate_parser.add_argument("--fail-on-warning", action="store_true", help="Exit with code 2 on warnings")
    validate_parser.add_argument("--json", action="store_true", help="JSON output format")
    validate_parser.add_argument("--format", choices=["terminal", "json"], help="Output format (deprecated: use --json)")

    # stats command
    stats_parser = subparsers.add_parser("stats", help="Show statistics across specs")
    stats_parser.add_argument("--dir", default=".openspec", help="Spec directory (default: .openspec)")
    stats_parser.add_argument("--project-folder", default=".", help="Project root directory")

    # coverage command
    coverage_parser = subparsers.add_parser("coverage", help="Show reference coverage report")
    coverage_parser.add_argument("--dir", default=".openspec", help="Spec directory (default: .openspec)")
    coverage_parser.add_argument("--project-folder", default=".", help="Project root directory")
    coverage_parser.add_argument("--verbose", "-v", action="store_true", help="Show specs without coverage")

    # check-links command
    check_links_parser = subparsers.add_parser("check-links", help="Validate all reference links")
    check_links_parser.add_argument("--dir", default=".openspec", help="Spec directory (default: .openspec)")
    check_links_parser.add_argument("--project-folder", default=".", help="Project root directory")

    # rules command
    rules_parser = subparsers.add_parser("rules", help="Manage validation rules")
    rules_subparsers = rules_parser.add_subparsers(dest="rules_command")
    rules_show_parser = rules_subparsers.add_parser("show", help="Show active rules")
    rules_show_parser.add_argument("--dir", default=".openspec", help="Spec directory")

    args = parser.parse_args()

    # Set global RAW_MODE flag
    global RAW_MODE
    RAW_MODE = args.raw

    # Default to browse if no command specified
    if not args.command:
        args.command = "browse"
        # Add default attributes for browse command
        if not hasattr(args, 'dir'):
            args.dir = ".openspec"
        if not hasattr(args, 'project_folder'):
            args.project_folder = "."
        if not hasattr(args, 'edit'):
            args.edit = False

    # Route to command handlers
    if args.command == "browse":
        cmd_browse(args)
    elif args.command == "list":
        cmd_list(args)
    elif args.command == "status":
        cmd_status(args)
    elif args.command == "template":
        cmd_template(args)
    elif args.command == "new":
        cmd_new(args)
    elif args.command == "init":
        cmd_init(args)
    elif args.command == "validate":
        cmd_validate(args)
    elif args.command == "stats":
        cmd_stats(args)
    elif args.command == "coverage":
        cmd_coverage(args)
    elif args.command == "check-links":
        cmd_check_links(args)
    elif args.command == "rules":
        if args.rules_command == "show":
            cmd_rules_show(args)
        else:
            rules_parser.print_help()
    else:
        parser.print_help()

if __name__ == "__main__":
    main()
